{
  
    
        "post0": {
            "title": "Title",
            "content": "!pip install -Uqq fastbook import fastbook #fastbook.setup_book() . |████████████████████████████████| 727kB 7.7MB/s |████████████████████████████████| 51kB 8.4MB/s |████████████████████████████████| 204kB 18.7MB/s |████████████████████████████████| 1.2MB 18.9MB/s |████████████████████████████████| 61kB 9.5MB/s |████████████████████████████████| 51kB 8.3MB/s . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . #!unzip -u &quot;/content/drive/My Drive/Deep/TrainImages.zip&quot; -d &quot;/content/drive/My Drive/Deep/Birdsounds&quot; !unzip -u &quot;/content/drive/My Drive/Deep/Bird500.zip&quot; -d &quot;/content/drive/My Drive/Deep/Birdsounds/train_short_audio&quot; . Archive: /content/drive/My Drive/Deep/Bird500.zip warning [/content/drive/My Drive/Deep/Bird500.zip]: 45317897 extra bytes at beginning or within zipfile (attempting to process anyway) error [/content/drive/My Drive/Deep/Bird500.zip]: start of central directory not found; zipfile corrupt. (please check that you have transferred or created the zipfile in the appropriate BINARY mode and that you have compiled UnZip properly) . import pandas as pd import numpy as np import librosa import librosa.display import IPython.display as ipd import matplotlib.pyplot as plt import shutil, math, os . root = &#39;/content/drive/My Drive/Deep/&#39; audio_path = root + &#39;Birdsounds/train_short_audio/&#39; test_path = audio_path + &#39;XC1619.ogg&#39; image_path = root + &#39;Images/&#39; . ipd.Audio(test_path) . Your browser does not support the audio element. librosa.get_duration(filename=test_path) . 82.11703125 . for recording in os.listdir(audio_path): filepath = audio_path + recording filename = recording.split(&#39;.&#39;)[0] offset = 0 duration = 10 for i in range(math.floor(librosa.get_duration(filename=filepath)/duration)): imagename = root + f&#39;Images/{filename}-{offset}-{offset + duration}.png&#39; if os.path.exists(imagename) : continue sig, rate = librosa.load(filepath, sr=32000, offset=offset, duration=duration) # First, compute the spectrogram using the &quot;short-time Fourier transform&quot; (stft) spec = librosa.stft(sig) # Scale the amplitudes according to the decibel scale spec_db = librosa.amplitude_to_db(spec, ref=np.max) # Plot the spectrogram plt.figure(figsize=(15, 5)) librosa.display.specshow(spec_db, sr=32000, x_axis=&#39;time&#39;, y_axis=&#39;hz&#39;, cmap=plt.get_cmap(&#39;viridis&#39;)) plt.savefig(imagename) plt.clf() plt.close(&#39;all&#39;) offset += duration . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-8-cc12a94c0c69&gt; in &lt;module&gt;() 4 offset = 0 5 duration = 10 -&gt; 6 for i in range(math.floor(librosa.get_duration(filename=filepath)/duration)): 7 imagename = root + f&#39;Images/{filename}-{offset}-{offset + duration}.png&#39; 8 if os.path.exists(imagename) : continue /usr/local/lib/python3.7/dist-packages/librosa/core/audio.py in get_duration(y, sr, S, n_fft, hop_length, center, filename) 677 if filename is not None: 678 try: --&gt; 679 return sf.info(filename).duration 680 except RuntimeError: 681 with audioread.audio_open(filename) as fdesc: /usr/local/lib/python3.7/dist-packages/soundfile.py in info(file, verbose) 436 Whether to print additional information. 437 &#34;&#34;&#34; --&gt; 438 return _SoundFileInfo(file, verbose) 439 440 /usr/local/lib/python3.7/dist-packages/soundfile.py in __init__(self, file, verbose) 381 def __init__(self, file, verbose): 382 self.verbose = verbose --&gt; 383 with SoundFile(file) as f: 384 self.name = f.name 385 self.samplerate = f.samplerate /usr/local/lib/python3.7/dist-packages/soundfile.py in __init__(self, file, mode, samplerate, channels, subtype, endian, format, closefd) 627 self._info = _create_info_struct(file, mode, samplerate, channels, 628 format, subtype, endian) --&gt; 629 self._file = self._open(file, mode_int, closefd) 630 if set(mode).issuperset(&#39;r+&#39;) and self.seekable(): 631 # Move write position to 0 (like in Python file objects) /usr/local/lib/python3.7/dist-packages/soundfile.py in _open(self, file, mode_int, closefd) 1173 else: 1174 file = file.encode(_sys.getfilesystemencoding()) -&gt; 1175 file_ptr = openfunction(file, mode_int, self._info) 1176 elif isinstance(file, int): 1177 file_ptr = _snd.sf_open_fd(file, mode_int, self._info, closefd) KeyboardInterrupt: . meta_df = pd.read_csv(root+&#39;train_metadata.csv&#39;) bird500 = meta_df[meta_df[&#39;primary_label&#39;].map(meta_df[&#39;primary_label&#39;].value_counts()) == 500] bird500_gb = bird500.groupby(&#39;primary_label&#39;).apply(lambda x: x.sample(100, random_state=42)) offset = 2 duration = 10 for i, row in bird500_gb.iterrows(): bird = row.primary_label file = row.filename filepath = audio_path + f&#39;{bird}/{file}&#39; filename = file.split(&#39;.&#39;)[0] imagename = root + f&#39;TrainImages/{filename}.png&#39; sig, rate = librosa.load(filepath, sr=32000, offset=offset, duration=duration) # First, compute the spectrogram using the &quot;short-time Fourier transform&quot; (stft) spec = librosa.stft(sig) # Scale the amplitudes according to the decibel scale spec_db = librosa.amplitude_to_db(spec, ref=np.max) # Plot the spectrogram plt.figure(figsize=(15, 5)) librosa.display.specshow(spec_db, sr=32000, x_axis=&#39;time&#39;, y_axis=&#39;hz&#39;, cmap=plt.get_cmap(&#39;viridis&#39;)) plt.savefig(imagename) plt.clf() plt.close(&#39;all&#39;) . /usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead. warnings.warn(&#34;PySoundFile failed. Trying audioread instead.&#34;) . RuntimeError Traceback (most recent call last) /usr/local/lib/python3.7/dist-packages/librosa/core/audio.py in load(path, sr, mono, offset, duration, dtype, res_type) 145 try: --&gt; 146 with sf.SoundFile(path) as sf_desc: 147 sr_native = sf_desc.samplerate /usr/local/lib/python3.7/dist-packages/soundfile.py in __init__(self, file, mode, samplerate, channels, subtype, endian, format, closefd) 628 format, subtype, endian) --&gt; 629 self._file = self._open(file, mode_int, closefd) 630 if set(mode).issuperset(&#39;r+&#39;) and self.seekable(): /usr/local/lib/python3.7/dist-packages/soundfile.py in _open(self, file, mode_int, closefd) 1183 _error_check(_snd.sf_error(file_ptr), -&gt; 1184 &#34;Error opening {0!r}: &#34;.format(self.name)) 1185 if mode_int == _snd.SFM_WRITE: /usr/local/lib/python3.7/dist-packages/soundfile.py in _error_check(err, prefix) 1356 err_str = _snd.sf_error_number(err) -&gt; 1357 raise RuntimeError(prefix + _ffi.string(err_str).decode(&#39;utf-8&#39;, &#39;replace&#39;)) 1358 RuntimeError: Error opening &#39;/content/drive/My Drive/Deep/Birdsounds/train_short_audio/barswa/XC484700.ogg&#39;: System error. During handling of the above exception, another exception occurred: FileNotFoundError Traceback (most recent call last) &lt;ipython-input-12-0d8979d2f23c&gt; in &lt;module&gt;() 14 15 imagename = root + f&#39;TrainImages/{filename}.png&#39; &gt; 16 sig, rate = librosa.load(filepath, sr=32000, offset=offset, duration=duration) 17 18 # First, compute the spectrogram using the &#34;short-time Fourier transform&#34; (stft) /usr/local/lib/python3.7/dist-packages/librosa/core/audio.py in load(path, sr, mono, offset, duration, dtype, res_type) 161 if isinstance(path, (str, pathlib.PurePath)): 162 warnings.warn(&#34;PySoundFile failed. Trying audioread instead.&#34;) --&gt; 163 y, sr_native = __audioread_load(path, offset, duration, dtype) 164 else: 165 raise (exc) /usr/local/lib/python3.7/dist-packages/librosa/core/audio.py in __audioread_load(path, offset, duration, dtype) 185 186 y = [] --&gt; 187 with audioread.audio_open(path) as input_file: 188 sr_native = input_file.samplerate 189 n_channels = input_file.channels /usr/local/lib/python3.7/dist-packages/audioread/__init__.py in audio_open(path, backends) 109 for BackendClass in backends: 110 try: --&gt; 111 return BackendClass(path) 112 except DecodeError: 113 pass /usr/local/lib/python3.7/dist-packages/audioread/rawread.py in __init__(self, filename) 60 &#34;&#34;&#34; 61 def __init__(self, filename): &gt; 62 self._fh = open(filename, &#39;rb&#39;) 63 64 try: FileNotFoundError: [Errno 2] No such file or directory: &#39;/content/drive/My Drive/Deep/Birdsounds/train_short_audio/barswa/XC484700.ogg&#39; . import os len(os.listdir(&#39;/content/drive/My Drive/Deep/Birdsounds/TrainImages&#39;)) . 241 . from fastai.vision.all import * . meta_df = pd.read_csv(root + &#39;train_metadata.csv&#39;) meta_df.head() . primary_label secondary_labels type latitude longitude scientific_name common_name author date filename license rating time url . 0 acafly | [&#39;amegfi&#39;] | [&#39;begging call&#39;, &#39;call&#39;, &#39;juvenile&#39;] | 35.3860 | -84.1250 | Empidonax virescens | Acadian Flycatcher | Mike Nelson | 2012-08-12 | XC109605.ogg | Creative Commons Attribution-NonCommercial-ShareAlike 3.0 | 2.5 | 09:30 | https://www.xeno-canto.org/109605 | . 1 acafly | [] | [&#39;call&#39;] | 9.1334 | -79.6501 | Empidonax virescens | Acadian Flycatcher | Allen T. Chartier | 2000-12-26 | XC11209.ogg | Creative Commons Attribution-NonCommercial-ShareAlike 3.0 | 3.0 | ? | https://www.xeno-canto.org/11209 | . 2 acafly | [] | [&#39;call&#39;] | 5.7813 | -75.7452 | Empidonax virescens | Acadian Flycatcher | Sergio Chaparro-Herrera | 2012-01-10 | XC127032.ogg | Creative Commons Attribution-NonCommercial-ShareAlike 3.0 | 3.0 | 15:20 | https://www.xeno-canto.org/127032 | . 3 acafly | [&#39;whwbec1&#39;] | [&#39;call&#39;] | 4.6717 | -75.6283 | Empidonax virescens | Acadian Flycatcher | Oscar Humberto Marin-Gomez | 2009-06-19 | XC129974.ogg | Creative Commons Attribution-NonCommercial-ShareAlike 3.0 | 3.5 | 07:50 | https://www.xeno-canto.org/129974 | . 4 acafly | [&#39;whwbec1&#39;] | [&#39;call&#39;] | 4.6717 | -75.6283 | Empidonax virescens | Acadian Flycatcher | Oscar Humberto Marin-Gomez | 2009-06-19 | XC129981.ogg | Creative Commons Attribution-NonCommercial-ShareAlike 3.0 | 3.5 | 07:50 | https://www.xeno-canto.org/129981 | . def get_bird_label(file): file = str(file.parts[-1]) filename = file.split(&#39;-&#39;)[0] + &#39;.ogg&#39; bird_label = meta_df[meta_df[&#39;filename&#39;] == filename][&#39;primary_label&#39;].values[0] return bird_label . fns = get_image_files(image_path) fns . failed = verify_images(fns) failed . (#0) [] . failed.map(Path.unlink); . birds = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=get_bird_label, item_tfms=RandomResizedCrop(128)) . dls = birds.dataloaders(image_path) . learn = cnn_learner(dls, resnet152, metrics=error_rate).to_fp16() learn.fit_one_cycle(4) learn.unfreeze() learn.fit_one_cycle(4) . . 0.00% [0/4 00:00&lt;00:00] epoch train_loss valid_loss error_rate time . . 98.52% [266/270 1:06:19&lt;00:59 2.3173] &lt;/div&gt; &lt;/div&gt; OSError Traceback (most recent call last) &lt;ipython-input-10-a6fb24dab211&gt; in &lt;module&gt;() 1 learn = cnn_learner(dls, resnet152, metrics=error_rate) -&gt; 2 learn.fit_one_cycle(4) 3 learn.unfreeze() 4 learn.fit_one_cycle(4) /usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt) 110 scheds = {&#39;lr&#39;: combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final), 111 &#39;mom&#39;: combined_cos(pct_start, *(self.moms if moms is None else moms))} --&gt; 112 self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd) 113 114 # Cell /usr/local/lib/python3.7/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt) 216 self.opt.set_hypers(lr=self.lr if lr is None else lr) 217 self.n_epoch = n_epoch --&gt; 218 self._with_events(self._do_fit, &#39;fit&#39;, CancelFitException, self._end_cleanup) 219 220 def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_fit(self) 207 for epoch in range(self.n_epoch): 208 self.epoch=epoch --&gt; 209 self._with_events(self._do_epoch, &#39;epoch&#39;, CancelEpochException) 210 211 def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch(self) 201 202 def _do_epoch(self): --&gt; 203 self._do_epoch_train() 204 self._do_epoch_validate() 205 /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _do_epoch_train(self) 193 def _do_epoch_train(self): 194 self.dl = self.dls.train --&gt; 195 self._with_events(self.all_batches, &#39;train&#39;, CancelTrainException) 196 197 def _do_epoch_validate(self, ds_idx=1, dl=None): /usr/local/lib/python3.7/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final) 158 159 def _with_events(self, f, event_type, ex, final=noop): --&gt; 160 try: self(f&#39;before_{event_type}&#39;); f() 161 except ex: self(f&#39;after_cancel_{event_type}&#39;) 162 self(f&#39;after_{event_type}&#39;); final() /usr/local/lib/python3.7/dist-packages/fastai/learner.py in all_batches(self) 164 def all_batches(self): 165 self.n_iter = len(self.dl) --&gt; 166 for o in enumerate(self.dl): self.one_batch(*o) 167 168 def _do_one_batch(self): /usr/local/lib/python3.7/dist-packages/fastai/data/load.py in __iter__(self) 107 self.before_iter() 108 self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses) --&gt; 109 for b in _loaders[self.fake_l.num_workers==0](self.fake_l): 110 if self.device is not None: b = to_device(b, self.device) 111 yield self.after_batch(b) /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in __next__(self) 515 if self._sampler_iter is None: 516 self._reset() --&gt; 517 data = self._next_data() 518 self._num_yielded += 1 519 if self._dataset_kind == _DatasetKind.Iterable and /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in _next_data(self) 1197 else: 1198 del self._task_info[idx] -&gt; 1199 return self._process_data(data) 1200 1201 def _try_put_index(self): /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py in _process_data(self, data) 1223 self._try_put_index() 1224 if isinstance(data, ExceptionWrapper): -&gt; 1225 data.reraise() 1226 return data 1227 /usr/local/lib/python3.7/dist-packages/torch/_utils.py in reraise(self) 427 # have message field 428 raise self.exc_type(message=msg) --&gt; 429 raise self.exc_type(msg) 430 431 OSError: Caught OSError in DataLoader worker process 0. Original Traceback (most recent call last): File &#34;/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py&#34;, line 202, in _worker_loop data = fetcher.fetch(index) File &#34;/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py&#34;, line 34, in fetch data = next(self.dataset_iter) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/load.py&#34;, line 118, in create_batches yield from map(self.do_batch, self.chunkify(res)) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/basics.py&#34;, line 216, in chunked res = list(itertools.islice(it, chunk_sz)) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/load.py&#34;, line 133, in do_item try: return self.after_item(self.create_item(s)) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/load.py&#34;, line 140, in create_item if self.indexed: return self.dataset[s or 0] File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/core.py&#34;, line 333, in __getitem__ res = tuple([tl[it] for tl in self.tls]) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/core.py&#34;, line 333, in &lt;listcomp&gt; res = tuple([tl[it] for tl in self.tls]) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/core.py&#34;, line 299, in __getitem__ return self._after_item(res) if is_indexer(idx) else res.map(self._after_item) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/data/core.py&#34;, line 261, in _after_item def _after_item(self, o): return self.tfms(o) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/transform.py&#34;, line 200, in __call__ def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/transform.py&#34;, line 150, in compose_tfms x = f(x, **kwargs) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/transform.py&#34;, line 73, in __call__ def __call__(self, x, **kwargs): return self._call(&#39;encodes&#39;, x, **kwargs) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/transform.py&#34;, line 83, in _call return self._do_call(getattr(self, fn), x, **kwargs) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/transform.py&#34;, line 89, in _do_call return retain_type(f(x, **kwargs), x, ret) File &#34;/usr/local/lib/python3.7/dist-packages/fastcore/dispatch.py&#34;, line 118, in __call__ return f(*args, **kwargs) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/vision/core.py&#34;, line 110, in create return cls(load_image(fn, **merge(cls._open_args, kwargs))) File &#34;/usr/local/lib/python3.7/dist-packages/fastai/vision/core.py&#34;, line 86, in load_image im.load() File &#34;/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py&#34;, line 270, in load raise_ioerror(err_code) File &#34;/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py&#34;, line 59, in raise_ioerror raise OSError(message + &#34; when reading image file&#34;) OSError: unrecognized data stream contents when reading image file . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(5, nrows=1) . &lt;/div&gt; .",
            "url": "https://markbringnielsen.github.io/BirdsBlog/2021/05/25/Birds.html",
            "relUrl": "/2021/05/25/Birds.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://markbringnielsen.github.io/BirdsBlog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://markbringnielsen.github.io/BirdsBlog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://markbringnielsen.github.io/BirdsBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://markbringnielsen.github.io/BirdsBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}